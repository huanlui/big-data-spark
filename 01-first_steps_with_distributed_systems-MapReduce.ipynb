{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42);\n",
    "\n",
    "list_of_cakes = [random.choice([\n",
    "    'sacher',\n",
    "    'santiago',\n",
    "    'san_marcos',\n",
    "    'coca'])\n",
    "    for _ in range(100)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sacher',\n",
       " 'sacher',\n",
       " 'san_marcos',\n",
       " 'santiago',\n",
       " 'santiago',\n",
       " 'santiago',\n",
       " 'sacher',\n",
       " 'sacher',\n",
       " 'coca',\n",
       " 'sacher']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_cakes[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://juans-mbp:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto, como no tengo ningún clúster, lo va a usar como si fuera un clúster. Un clúster por núcleo del ordenador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_first_rdd = sc.parallelize(list_of_cakes)\n",
    "type(my_first_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_first_rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yo tengo 6 núcleos, ynme ha creado 12. No es directamente una relación 1 a 1 ni 1 a X. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No sobreescribir usando my_first_rdd = my_first_rdd.map... Son inmutables. Aunque no acabo de pillarlo, porque sería sólo la referencia... A lo mejor van por valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_second_rdd = my_first_rdd.map(lambda x: x + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_second_rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map es una transformación, no una acción. Esto es equivalente a lazy e eager operations en Linq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto ya haría que se ejecutara:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_second_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio: filtrar los pasteles que no empiezan por s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_starting_with_s = my_first_rdd.filter(lambda x : x[0] != 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 3 sólo coge 3 y ya no sigue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coca', 'coca', 'coca']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_starting_with_s.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect es dame todo lo que tienen las particiones, que yo me lo guardo en mi RAM. Si el tamaño es considerable, se queda pillado, porque el master no va a tener suficiente ram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coca',\n",
       " 'coca',\n",
       " 'coca',\n",
       " 'coca',\n",
       " 'coca',\n",
       " 'coca',\n",
       " 'coca',\n",
       " 'coca',\n",
       " 'coca',\n",
       " 'coca',\n",
       " 'coca',\n",
       " 'coca',\n",
       " 'coca',\n",
       " 'coca',\n",
       " 'coca',\n",
       " 'coca',\n",
       " 'coca',\n",
       " 'coca',\n",
       " 'coca',\n",
       " 'coca']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_starting_with_s.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_starting_with_s.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo normal es hacerlo estilo C#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cocas',\n",
       " 'cocas',\n",
       " 'cocas',\n",
       " 'cocas',\n",
       " 'cocas',\n",
       " 'cocas',\n",
       " 'cocas',\n",
       " 'cocas',\n",
       " 'cocas',\n",
       " 'cocas',\n",
       " 'cocas',\n",
       " 'cocas',\n",
       " 'cocas',\n",
       " 'cocas',\n",
       " 'cocas',\n",
       " 'cocas',\n",
       " 'cocas',\n",
       " 'cocas',\n",
       " 'cocas',\n",
       " 'cocas']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_first_rdd\\\n",
    "    .filter(lambda cake: cake[0] != 's')\\\n",
    "    .map(lambda x: x + 's')\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qué pasa si no me cabe en RAM?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedo escribir en disco, pero la cosa empezasrá a ir lento\n",
    "\n",
    "(Ver solución)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, persist me permite guardar un estado por si em va a resultar interesamnte para operaciones posteriores. Esto prersiste en memoria por defecto o en disco si lo tiened así configurado y no cabe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair RDD\n",
    "\n",
    "SOn RDD que son un par de clave-valor (tanto clave como valor pueden ser objetos complejos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sacher', 1),\n",
       " ('sacher', 1),\n",
       " ('san_marcos', 1),\n",
       " ('santiago', 1),\n",
       " ('santiago', 1),\n",
       " ('santiago', 1),\n",
       " ('sacher', 1),\n",
       " ('sacher', 1),\n",
       " ('coca', 1),\n",
       " ('sacher', 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_rdd = my_first_rdd.map(lambda cake: (cake,1)) # devuelves una tupla. La clave es el nombre. \n",
    "pair_rdd.collect()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sacher', <pyspark.resultiterable.ResultIterable at 0x11e2f0fd0>),\n",
       " ('san_marcos', <pyspark.resultiterable.ResultIterable at 0x11e2f06d0>),\n",
       " ('santiago', <pyspark.resultiterable.ResultIterable at 0x11e2f9bd0>),\n",
       " ('coca', <pyspark.resultiterable.ResultIterable at 0x11dfc03d0>)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_rdd = pair_rdd.groupByKey()\n",
    "grouped_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esos iterables son listas de unos, en este caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sacher', 27), ('san_marcos', 24), ('santiago', 29), ('coca', 20)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_rdd.map(lambda tuple: (tuple[0],len(tuple[1]))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto anterior me mapea de una lista de tuplas nomre-grupo a una lista de tuplas nombre-tamaño_del_grupo\n",
    "\n",
    "NOTA: En el fondo, usando un map estamos haciendo una reducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce by key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sacher', 27), ('san_marcos', 24), ('santiago', 29), ('coca', 20)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_rdd.reduceByKey(lambda acc,x: acc + x).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply word count to a file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos saber cuántas veces aparece cada palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1609\r\n",
      "\r\n",
      "THE SONNETS\r\n",
      "\r\n",
      "by William Shakespeare\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "                     1\r\n",
      "  From fairest creatures we desire increase,\r\n"
     ]
    }
   ],
   "source": [
    "!head data/shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1609', '', 'THE SONNETS', '', 'by William Shakespeare']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_lines = sc.textFile('data/shakespeare.txt')\n",
    "shakespeare_lines.take(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el take coge las primeras 5 palabras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = shakespeare_lines.map(lambda word : word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1609', '', 'the sonnets', '', 'by william shakespeare']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mi solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 505702), ('the', 27267), ('and', 25340), ('i', 19540), ('to', 18656)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_lines\\\n",
    "    .map(lambda line : line.lower())\\\n",
    "    .flatMap(lambda line : line.split(\" \"))\\\n",
    "    .map(lambda word: (word,1))\\\n",
    "    .groupByKey()\\\n",
    "    .map(lambda tuple: (tuple[0],len(tuple[1])))\\\n",
    "    .sortBy(lambda tuple : -tuple[1])\\\n",
    "    .take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejor usar reduceByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 505702), ('the', 27267), ('and', 25340), ('i', 19540), ('to', 18656)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_lines\\\n",
    "    .map(lambda line : line.lower())\\\n",
    "    .flatMap(lambda line : line.split(\" \"))\\\n",
    "    .map(lambda word: (word,1))\\\n",
    "    .reduceByKey(lambda acc,x: acc + x)\\\n",
    "    .sortBy(lambda tuple : -tuple[1])\\\n",
    "    .take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de dataframes en lugar de DDR (SparkSQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es más sencillo y sigue estando optimizado por detrás. No te tienes que preocupar. Por debajo están los RDDs y tú te abstraes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "session = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://juans-mbp:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11faede50>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.host', 'juans-mbp'),\n",
       " ('spark.driver.port', '50370'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.app.id', 'local-1571478677006'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.name', 'PySparkShell'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['manager',\n",
       " 'mecanic',\n",
       " 'mecanic',\n",
       " 'manager',\n",
       " 'sales',\n",
       " 'mecanic',\n",
       " 'mecanic',\n",
       " 'mecanic',\n",
       " 'manager',\n",
       " 'mecanic',\n",
       " 'manager',\n",
       " 'manager']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "ids = range(12)\n",
    "positions = [random.choice(['mecanic','sales','manager']) for id__ in ids]\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x11f9c3910>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = zip(ids,positions)\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_1: bigint, _2: string]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = session.createDataFrame(rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La línea anterior tarda porque esta preparando las cosas, los RDD por debajo, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_1=0, _2='manager'),\n",
       " Row(_1=1, _2='mecanic'),\n",
       " Row(_1=2, _2='mecanic'),\n",
       " Row(_1=3, _2='manager'),\n",
       " Row(_1=4, _2='sales')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDf = session.createDataFrame(zip(ids,positions),schema=['id','position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|position|\n",
      "+---+--------+\n",
      "|  0| manager|\n",
      "|  1| mecanic|\n",
      "|  2| mecanic|\n",
      "|  3| manager|\n",
      "|  4|   sales|\n",
      "+---+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
