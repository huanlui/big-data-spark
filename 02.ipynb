{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'warrior'),\n",
       " (1, 'wizard'),\n",
       " (2, 'wizard'),\n",
       " (3, 'priest'),\n",
       " (4, 'warrior'),\n",
       " (5, 'warrior'),\n",
       " (6, 'warrior'),\n",
       " (7, 'priest'),\n",
       " (8, 'warrior'),\n",
       " (9, 'wizard'),\n",
       " (10, 'priest'),\n",
       " (11, 'wizard')]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(23)\n",
    "ids = range(12)\n",
    "data = [ (id_,random.choice(['wizard','warrior','priest'])) for id_ in ids]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto sería para crear un RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los RDD son más lentos en Python porque no es tipado. Eso no pasa en escala. Además, nosotros querremos trabajar con _tablas_, no con _listas_ de datos. Un RDD tendría sentido por ejemplo si quiero trabajar con una lista  de logs, por ejemplo, pero para datos con varias propiedades, deberíamos usar dataframes, porque son mcuho más fáciles y naturales de usar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: long (nullable = true)\n",
      " |-- _2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí los nombres los está poniendo a capón, está infiriendo el esquema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos elegirlo nosotros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, category: string]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(data, schema=['id', 'category'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por debajo, los dataframes usan RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[631] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=0, category='warrior'),\n",
       " Row(id=1, category='wizard'),\n",
       " Row(id=2, category='wizard'),\n",
       " Row(id=3, category='priest'),\n",
       " Row(id=4, category='warrior')]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id=0, category='warrior')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onerow = df.first()\n",
    "onerow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se recomienda hacer lo siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'warrior'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onerow.category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recomiendo mejor hacer esto, porque hay nombres complejos. No sé si estoy de acuerdo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'warrior'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onerow['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos especificar el esquema con más detalle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando nosotros estamos usando pyspark, en el fondo acabamos llamando a Java (Scala está montada sobre Java). Py4Java permite llamar a código Java usando python y eso es lo que usa pyspark por debajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(id,IntegerType,false),StructField(category,StringType,true)))"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import types\n",
    "\n",
    "schema_type = types.StructType([\n",
    "    types.StructField('id', types.IntegerType(), nullable = False),\n",
    "    types.StructField('category', types.StringType(), nullable = True),\n",
    "])\n",
    "\n",
    "schema_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data,schema=schema_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = false)\n",
      " |-- category: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leyendo desde csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: bigint, _c1: int, _c2: string, _c3: string, _c4: string, _c5: string, _c6: double, _c7: string, _c8: int, _c9: string, _c10: string, _c11: string, _c12: int, _c13: string, _c14: string]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.csv('data/coupon150720.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string, _c6: string, _c7: string, _c8: string, _c9: string, _c10: string, _c11: string, _c12: string, _c13: string, _c14: string]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM csv.`data/coupon150720.csv`')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es util para gente que no tiene mucha idea de programar pero si de SQL o para directamente filtrar datos que no me interesan ya durantre el proceso de lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79062005698500,1,MAA,AUH,9W,9W,56.79,USD,1,H,H,0526,150904,OK,IAF0\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 data/coupon150720.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[tft_number: string, coupon_number: string, origin: string, amount: string]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('''SELECT  \n",
    "            _c0 AS tft_number,\n",
    "            _c1 AS coupon_number,\n",
    "            _c2 AS origin,\n",
    "            _c3 AS amount\n",
    "            FROM csv.`data/coupon150720.csv`''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones sobre dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|category|\n",
      "+---+--------+\n",
      "|  0| warrior|\n",
      "|  1|  wizard|\n",
      "|  2|  wizard|\n",
      "|  3|  priest|\n",
      "|  4| warrior|\n",
      "|  5| warrior|\n",
      "|  6| warrior|\n",
      "|  7|  priest|\n",
      "|  8| warrior|\n",
      "|  9|  wizard|\n",
      "| 10|  priest|\n",
      "| 11|  wizard|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|category|\n",
      "+--------+\n",
      "| warrior|\n",
      "|  wizard|\n",
      "|  wizard|\n",
      "|  priest|\n",
      "| warrior|\n",
      "| warrior|\n",
      "| warrior|\n",
      "|  priest|\n",
      "| warrior|\n",
      "|  wizard|\n",
      "|  priest|\n",
      "|  wizard|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('category').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[category: string]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'category'>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas dos operaciones no son equivalente. De hecho, no puedo hacer por ejemplo el .show(). Es una referencia a la columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['category'].show() # cascaría"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|category|\n",
      "+---+--------+\n",
      "|  6| warrior|\n",
      "|  7|  priest|\n",
      "|  8| warrior|\n",
      "|  9|  wizard|\n",
      "| 10|  priest|\n",
      "| 11|  wizard|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['id'] > 5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Where` hace lo mismo, pero el nombre es más _funcional_. De hecho, aquí me dice que lo encapsula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method filter of DataFrame[id: int, category: string]>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.where"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio: extraer ids que correspondan a priest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  3|\n",
      "|  7|\n",
      "| 10|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df \\\n",
    ".where(df['category'] == 'priest') \\\n",
    ".select('id') \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra opción para usar select es usar el doble corchete. Recuerda que el corchete simple es solo para meterlo en filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  3|\n",
      "|  7|\n",
      "| 10|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df \\\n",
    ".where(df['category'] == 'priest') \\\n",
    "[['id']] \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los dataframe son inmutables. Por tanto, no puedo hacer cosas como esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['new_column'] = df['id']  * 100 (casca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo correcto sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, category: string, (id * 100): int]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('id', 'category', df['id'] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra opción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+\n",
      "| id|category|new_column|\n",
      "+---+--------+----------+\n",
      "|  0| warrior|         0|\n",
      "|  1|  wizard|       100|\n",
      "|  2|  wizard|       200|\n",
      "|  3|  priest|       300|\n",
      "|  4| warrior|       400|\n",
      "|  5| warrior|       500|\n",
      "|  6| warrior|       600|\n",
      "|  7|  priest|       700|\n",
      "|  8| warrior|       800|\n",
      "|  9|  wizard|       900|\n",
      "| 10|  priest|      1000|\n",
      "| 11|  wizard|      1100|\n",
      "+---+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('new_column',df['id'] * 100).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTA__: Ojo, todo esto no está ocupando memoria. Por ejemplo, cuando he creado la dataframe a partir del csv, lo que se almacena es que estamos haciendo referencia a un  path de csv. Es a la hora de hacer un take o similar cuando realmente lee de ese fichero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer transformaciones en columnas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log hace el logaritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|           LOG(id)|\n",
      "+------------------+\n",
      "|              null|\n",
      "|               0.0|\n",
      "|0.6931471805599453|\n",
      "|1.0986122886681098|\n",
      "|1.3862943611198906|\n",
      "|1.6094379124341003|\n",
      "| 1.791759469228055|\n",
      "|1.9459101490553132|\n",
      "|2.0794415416798357|\n",
      "|2.1972245773362196|\n",
      "| 2.302585092994046|\n",
      "|2.3978952727983707|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[[functions.log('id')]].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra opción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|           LOG(id)|\n",
      "+------------------+\n",
      "|              null|\n",
      "|               0.0|\n",
      "|0.6931471805599453|\n",
      "|1.0986122886681098|\n",
      "|1.3862943611198906|\n",
      "|1.6094379124341003|\n",
      "| 1.791759469228055|\n",
      "|1.9459101490553132|\n",
      "|2.0794415416798357|\n",
      "|2.1972245773362196|\n",
      "| 2.302585092994046|\n",
      "|2.3978952727983707|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(functions.log('id')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero quiero hacerme `mi propia función`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "| id|<lambda>(id)|\n",
      "+---+------------+\n",
      "|  0|           0|\n",
      "|  1|           1|\n",
      "|  2|           4|\n",
      "|  3|           9|\n",
      "|  4|          16|\n",
      "|  5|          25|\n",
      "|  6|          36|\n",
      "|  7|          49|\n",
      "|  8|          64|\n",
      "|  9|          81|\n",
      "| 10|         100|\n",
      "| 11|         121|\n",
      "+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mi_func = lambda x :  x * x\n",
    "mi_udf = functions.udf(mi_func)\n",
    "otro_df = df.select('id', mi_udf('id'))\n",
    "otro_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, <lambda>(id): string]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otro_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo jodido es que me pone la columna de tipo string el muy c... Esto es porque spark lo intenta inferir, perop python no tiene tipado estático. Spark tira por string \n",
    "\n",
    "```Esto con Scala no pasaba```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No es tan dramático, lo puedo solucionar fácil. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, <lambda>(id): int]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_func = lambda x :  x * x\n",
    "mi_udf = functions.udf(mi_func, returnType=types.IntegerType())\n",
    "df.select('id', mi_udf('id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear una columna puntos de vida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------------------------+\n",
      "| id|category|get_puntos_de_vida(category)|\n",
      "+---+--------+----------------------------+\n",
      "|  0| warrior|                          50|\n",
      "|  1|  wizard|                          34|\n",
      "|  2|  wizard|                          35|\n",
      "|  3|  priest|                          13|\n",
      "|  4| warrior|                          53|\n",
      "|  5| warrior|                          54|\n",
      "|  6| warrior|                          55|\n",
      "|  7|  priest|                          11|\n",
      "|  8| warrior|                          54|\n",
      "|  9|  wizard|                          34|\n",
      "| 10|  priest|                          14|\n",
      "| 11|  wizard|                          35|\n",
      "+---+--------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_puntos_de_vida(category):\n",
    "    random_deviation = round(random.random() * 5)\n",
    "    \n",
    "    if(category == 'priest'): return 10 + random_deviation\n",
    "    if(category == 'warrior'): return 50 + random_deviation\n",
    "    \n",
    "    return 30 + random_deviation\n",
    "\n",
    "df.select('id', 'category', functions.udf(get_puntos_de_vida)('category')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más elegante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+\n",
      "| id|category| hp|\n",
      "+---+--------+---+\n",
      "|  0| warrior| 50|\n",
      "|  1|  wizard| 30|\n",
      "|  2|  wizard| 30|\n",
      "|  3|  priest| 10|\n",
      "|  4| warrior| 50|\n",
      "|  5| warrior| 50|\n",
      "|  6| warrior| 50|\n",
      "|  7|  priest| 10|\n",
      "|  8| warrior| 50|\n",
      "|  9|  wizard| 30|\n",
      "| 10|  priest| 10|\n",
      "| 11|  wizard| 30|\n",
      "+---+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hp = functions.udf(lambda category: {'priest': 10, 'warrior': 50, 'wizard':30}[category])\n",
    "\n",
    "df.select('id', 'category', hp('category').cast(types.IntegerType()).alias('hp')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O incluso más bonito:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------+\n",
      "| id|category|puntos de vida|\n",
      "+---+--------+--------------+\n",
      "|  0| warrior|            50|\n",
      "|  1|  wizard|            30|\n",
      "|  2|  wizard|            30|\n",
      "|  3|  priest|            10|\n",
      "|  4| warrior|            50|\n",
      "|  5| warrior|            50|\n",
      "|  6| warrior|            50|\n",
      "|  7|  priest|            10|\n",
      "|  8| warrior|            50|\n",
      "|  9|  wizard|            30|\n",
      "| 10|  priest|            10|\n",
      "| 11|  wizard|            30|\n",
      "+---+--------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.withColumn('puntos de vida', hp('category').cast(types.IntegerType()))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadísticas de summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.dataframe.DataFrameStatFunctions at 0x11d950890>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Concepto__: Bloom filter: algoritmo que te permite calcular al vuelo (sin guardarte en memoria nada) la pertenecia a conjuntos de forma aproximada.  Da falsos positivos pero no da falsos negativos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.24161209862606872"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.stat.corr('id', 'puntos de vida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14.545454545454545"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.cov('id','puntos de vida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------+------+\n",
      "| id|category|puntos de vida|  land|\n",
      "+---+--------+--------------+------+\n",
      "|  0| warrior|            50|mordor|\n",
      "|  1|  wizard|            30|gondor|\n",
      "|  2|  wizard|            30|gondor|\n",
      "|  3|  priest|            10|gondor|\n",
      "|  4| warrior|            50|mordor|\n",
      "|  5| warrior|            50|gondor|\n",
      "|  6| warrior|            50|mordor|\n",
      "|  7|  priest|            10|mordor|\n",
      "|  8| warrior|            50|mordor|\n",
      "|  9|  wizard|            30|gondor|\n",
      "| 10|  priest|            10|mordor|\n",
      "| 11|  wizard|            30|mordor|\n",
      "+---+--------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "location_udf = functions.udf(lambda: random.choice(['gondor','mordor']))\n",
    "\n",
    "df3 = df2.withColumn('land', location_udf())\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+------+\n",
      "|category_land|gondor|mordor|\n",
      "+-------------+------+------+\n",
      "|       priest|     3|     0|\n",
      "|      warrior|     3|     2|\n",
      "|       wizard|     2|     2|\n",
      "+-------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.crosstab('category', 'land').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para abrir consola de spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://juans-mbp:4040'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.uiWebUrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------+------+\n",
      "| id|category|puntos de vida|  land|\n",
      "+---+--------+--------------+------+\n",
      "|  0| warrior|            50|mordor|\n",
      "|  1|  wizard|            30|mordor|\n",
      "|  2|  wizard|            30|gondor|\n",
      "|  3|  priest|            10|gondor|\n",
      "|  4| warrior|            50|mordor|\n",
      "|  5| warrior|            50|mordor|\n",
      "|  6| warrior|            50|gondor|\n",
      "|  7|  priest|            10|mordor|\n",
      "|  8| warrior|            50|gondor|\n",
      "|  9|  wizard|            30|mordor|\n",
      "| 10|  priest|            10|gondor|\n",
      "| 11|  wizard|            30|gondor|\n",
      "+---+--------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df3.groupby('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|category|max(id)|\n",
      "+--------+-------+\n",
      "|  priest|     10|\n",
      "| warrior|      8|\n",
      "|  wizard|     11|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "groups.max('id').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer varias agregaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------+\n",
      "|category|avg(puntos de vida)|max(id)|\n",
      "+--------+-------------------+-------+\n",
      "|  priest|               10.0|     10|\n",
      "| warrior|               50.0|      8|\n",
      "|  wizard|               30.0|     11|\n",
      "+--------+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "groups.agg({'id': 'max', 'puntos de vida': 'mean'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más flexible y bonita:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-------------------+-----------------+\n",
      "|category|max(id)|avg(puntos de vida)|          avg(id)|\n",
      "+--------+-------+-------------------+-----------------+\n",
      "|  priest|     10|               10.0|6.666666666666667|\n",
      "| warrior|      8|               50.0|              4.6|\n",
      "|  wizard|     11|               30.0|             5.75|\n",
      "+--------+-------+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "groups.agg(functions.max('id'), functions.mean('puntos de vida'), functions.mean('id')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puedo agrupar usando expresiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|(id > 5)|avg(puntos de vida)|\n",
      "+--------+-------------------+\n",
      "|    true|               30.0|\n",
      "|   false| 36.666666666666664|\n",
      "+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.groupBy(df['id'] > 5).mean('puntos de vida').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(19, 'gondor', 42000),\n",
       " (0, 'mordor', 37000),\n",
       " (8, 'gondor', 23000),\n",
       " (6, 'gondor', 16000),\n",
       " (22, 'mordor', 48000),\n",
       " (20, 'mordor', 23000),\n",
       " (26, 'gondor', 13000),\n",
       " (2, 'mordor', 13000),\n",
       " (12, 'mordor', 43000),\n",
       " (0, 'gondor', 34000)]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import seed\n",
    "from random import choices\n",
    "seed(42)\n",
    "\n",
    "data = list(zip(\n",
    "    choices(range(30),k=10),\n",
    "    choices(['gondor', 'mordor'], k=10),\n",
    "    choices(range(10000,50000, 1000), k=10)\n",
    "))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------+\n",
      "| id|  land|hp_bonus|\n",
      "+---+------+--------+\n",
      "| 19|gondor|   42000|\n",
      "|  0|mordor|   37000|\n",
      "|  8|gondor|   23000|\n",
      "|  6|gondor|   16000|\n",
      "| 22|mordor|   48000|\n",
      "| 20|mordor|   23000|\n",
      "| 26|gondor|   13000|\n",
      "|  2|mordor|   13000|\n",
      "| 12|mordor|   43000|\n",
      "|  0|gondor|   34000|\n",
      "+---+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "right = spark.createDataFrame(data, schema=['id', 'land', 'hp_bonus'])\n",
    "right.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto siguiente casca. Primero porque va a usar dos columnas, y segundo porque tenemos ids repetidos, detecta un prpducto cartesiano y casca porque en big data un producto cartesiano es una big shit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3.join(right).show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------+------+------+--------+\n",
      "| id|category|puntos de vida|  land|  land|hp_bonus|\n",
      "+---+--------+--------------+------+------+--------+\n",
      "| 26|    null|          null|  null|gondor|   13000|\n",
      "| 19|    null|          null|  null|gondor|   42000|\n",
      "|  0| warrior|            50|mordor|mordor|   37000|\n",
      "|  0| warrior|            50|mordor|gondor|   34000|\n",
      "| 22|    null|          null|  null|mordor|   48000|\n",
      "|  7|  priest|            10|mordor|  null|    null|\n",
      "|  6| warrior|            50|mordor|gondor|   16000|\n",
      "|  9|  wizard|            30|mordor|  null|    null|\n",
      "|  5| warrior|            50|gondor|  null|    null|\n",
      "|  1|  wizard|            30|gondor|  null|    null|\n",
      "| 10|  priest|            10|mordor|  null|    null|\n",
      "|  3|  priest|            10|gondor|  null|    null|\n",
      "| 12|    null|          null|  null|mordor|   43000|\n",
      "|  8| warrior|            50|gondor|gondor|   23000|\n",
      "| 11|  wizard|            30|gondor|  null|    null|\n",
      "|  2|  wizard|            30|mordor|mordor|   13000|\n",
      "|  4| warrior|            50|mordor|  null|    null|\n",
      "| 20|    null|          null|  null|mordor|   23000|\n",
      "+---+--------+--------------+------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined = df3.join(right, on='id', how='outer')\n",
    "joined.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto nos da dos columnas diferentes para land, una de una tabla y otra de la otra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para especificar a cual me refiero, tengo que especificar el dataframe del que quiero sacar la columna land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  land|\n",
      "+------+\n",
      "|  null|\n",
      "|  null|\n",
      "|mordor|\n",
      "|mordor|\n",
      "|  null|\n",
      "|mordor|\n",
      "|mordor|\n",
      "|mordor|\n",
      "|mordor|\n",
      "|gondor|\n",
      "|gondor|\n",
      "|gondor|\n",
      "|  null|\n",
      "|mordor|\n",
      "|gondor|\n",
      "|gondor|\n",
      "|mordor|\n",
      "|  null|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined.select(df3['land']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  land|\n",
      "+------+\n",
      "|gondor|\n",
      "|gondor|\n",
      "|mordor|\n",
      "|gondor|\n",
      "|mordor|\n",
      "|  null|\n",
      "|gondor|\n",
      "|  null|\n",
      "|  null|\n",
      "|  null|\n",
      "|  null|\n",
      "|  null|\n",
      "|mordor|\n",
      "|gondor|\n",
      "|  null|\n",
      "|mordor|\n",
      "|  null|\n",
      "|mordor|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined.select(right['land']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cacheo `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cachear por ejemplo este cache, usariamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, category: string, puntos de vida: int, land: string, land: string, hp_bonus: bigint]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero esto, si nos vamos a la seccion vemos que no nos aparece en el storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular la z score de puntos de vida de cada jugador para su tierra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------+------+\n",
      "| id|category|puntos de vida|  land|\n",
      "+---+--------+--------------+------+\n",
      "|  0| warrior|            50|mordor|\n",
      "|  1|  wizard|            30|mordor|\n",
      "|  2|  wizard|            30|gondor|\n",
      "|  3|  priest|            10|gondor|\n",
      "|  4| warrior|            50|mordor|\n",
      "|  5| warrior|            50|gondor|\n",
      "|  6| warrior|            50|gondor|\n",
      "|  7|  priest|            10|mordor|\n",
      "|  8| warrior|            50|mordor|\n",
      "|  9|  wizard|            30|gondor|\n",
      "| 10|  priest|            10|gondor|\n",
      "| 11|  wizard|            30|mordor|\n",
      "+---+--------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+------------------+\n",
      "|  land|               avg|            stddev|\n",
      "+------+------------------+------------------+\n",
      "|gondor|32.857142857142854|17.994708216848746|\n",
      "|mordor|              34.0| 16.73320053068151|\n",
      "+------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medias = df3.groupby('land') \\\n",
    ".agg(functions.avg('puntos de vida').alias('avg'), functions.stddev('puntos de vida').alias('stddev')) \n",
    "medias.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+--------+--------------+----+------------------+\n",
      "|  land| id|category|puntos de vida| avg|            stddev|\n",
      "+------+---+--------+--------------+----+------------------+\n",
      "|gondor|  1|  wizard|            30|37.5|  14.8804761828569|\n",
      "|gondor|  2|  wizard|            30|37.5|  14.8804761828569|\n",
      "|gondor|  5| warrior|            50|37.5|  14.8804761828569|\n",
      "|gondor|  7|  priest|            10|37.5|  14.8804761828569|\n",
      "|gondor|  9|  wizard|            30|37.5|  14.8804761828569|\n",
      "|gondor| 10|  priest|            10|37.5|  14.8804761828569|\n",
      "|gondor| 11|  wizard|            30|37.5|  14.8804761828569|\n",
      "|mordor|  0| warrior|            50|25.0|19.148542155126762|\n",
      "|mordor|  3|  priest|            10|25.0|19.148542155126762|\n",
      "|mordor|  4| warrior|            50|25.0|19.148542155126762|\n",
      "|mordor|  6| warrior|            50|25.0|19.148542155126762|\n",
      "|mordor|  8| warrior|            50|25.0|19.148542155126762|\n",
      "+------+---+--------+--------------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "annotated = df3.join(medias,on='land')\n",
    "annotated.cache() # si no cacheo, cambian los valores, porque esto es en streaming y tengo randoms por ahi. \n",
    "annotated.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora calculamos ya los z . Los podemos usar con aritmetica de columnas o con lambda. Lo primero es más eficiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+--------+--------------+----+------------------+-------------------+\n",
      "|  land| id|category|puntos de vida| avg|            stddev|            z-score|\n",
      "+------+---+--------+--------------+----+------------------+-------------------+\n",
      "|gondor|  1|  wizard|            30|37.5|  14.8804761828569|-0.5040161287741853|\n",
      "|gondor|  2|  wizard|            30|37.5|  14.8804761828569|-0.5040161287741853|\n",
      "|gondor|  5| warrior|            50|37.5|  14.8804761828569| 0.8400268812903088|\n",
      "|gondor|  7|  priest|            10|37.5|  14.8804761828569|-1.8480591388386793|\n",
      "|gondor|  9|  wizard|            30|37.5|  14.8804761828569|-0.5040161287741853|\n",
      "|gondor| 10|  priest|            10|37.5|  14.8804761828569|-1.8480591388386793|\n",
      "|gondor| 11|  wizard|            30|37.5|  14.8804761828569|-0.5040161287741853|\n",
      "|mordor|  0| warrior|            50|25.0|19.148542155126762| 1.3055824196677337|\n",
      "|mordor|  3|  priest|            10|25.0|19.148542155126762|-0.7833494518006403|\n",
      "|mordor|  4| warrior|            50|25.0|19.148542155126762| 1.3055824196677337|\n",
      "|mordor|  6| warrior|            50|25.0|19.148542155126762| 1.3055824196677337|\n",
      "|mordor|  8| warrior|            50|25.0|19.148542155126762| 1.3055824196677337|\n",
      "+------+---+--------+--------------+----+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = annotated.withColumn('z-score', (annotated['puntos de vida'] - annotated['avg']) / annotated['stddev'] )\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma (recordemos, algo más lenta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore = functions.udf(lambda xi, average, std: (xi - average) / std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+--------+--------------+----+------------------+-------------------+\n",
      "|  land| id|category|puntos de vida| avg|            stddev|            z-score|\n",
      "+------+---+--------+--------------+----+------------------+-------------------+\n",
      "|gondor|  1|  wizard|            30|37.5|  14.8804761828569|-0.5040161287741853|\n",
      "|gondor|  2|  wizard|            30|37.5|  14.8804761828569|-0.5040161287741853|\n",
      "|gondor|  5| warrior|            50|37.5|  14.8804761828569| 0.8400268812903088|\n",
      "|gondor|  7|  priest|            10|37.5|  14.8804761828569|-1.8480591388386793|\n",
      "|gondor|  9|  wizard|            30|37.5|  14.8804761828569|-0.5040161287741853|\n",
      "|gondor| 10|  priest|            10|37.5|  14.8804761828569|-1.8480591388386793|\n",
      "|gondor| 11|  wizard|            30|37.5|  14.8804761828569|-0.5040161287741853|\n",
      "|mordor|  0| warrior|            50|25.0|19.148542155126762| 1.3055824196677337|\n",
      "|mordor|  3|  priest|            10|25.0|19.148542155126762|-0.7833494518006403|\n",
      "|mordor|  4| warrior|            50|25.0|19.148542155126762| 1.3055824196677337|\n",
      "|mordor|  6| warrior|            50|25.0|19.148542155126762| 1.3055824196677337|\n",
      "|mordor|  8| warrior|            50|25.0|19.148542155126762| 1.3055824196677337|\n",
      "+------+---+--------+--------------+----+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result2 = annotated.withColumn('z-score', zscore('puntos de vida','avg', 'stddev'))\n",
    "result2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los null values, ver la solucion. Nada del otro mundo.\n",
    "\n",
    "Tenemos dropna que borra todos los que tenga alguna columna vacia. Es configurable, por ejemplo, puedo decir que sólo borre las que tenga todas nulas o le puedo poner un threshold para decir que si me paso de un número de columnas nulas, lo quite, si tiene menos, no. También puedo decir: descártame los que tengan nulos en el campo 'land''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL para consultar contra dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql('SELECT * FROM df3 where land = \"mordor\"') # esto falla, porque no encuentra una tabla df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------+------+\n",
      "| id|category|puntos de vida|  land|\n",
      "+---+--------+--------------+------+\n",
      "|  0| warrior|            50|gondor|\n",
      "|  2|  wizard|            30|mordor|\n",
      "|  3|  priest|            10|gondor|\n",
      "|  4| warrior|            50|gondor|\n",
      "|  5| warrior|            50|gondor|\n",
      "|  6| warrior|            50|mordor|\n",
      "|  9|  wizard|            30|mordor|\n",
      "+---+--------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.registerTempTable('tocoto')\n",
    "spark.sql('SELECT * FROM tocoto where land = \"mordor\"').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interoperacion con Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>land</th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>puntos de vida</th>\n",
       "      <th>avg</th>\n",
       "      <th>stddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gondor</td>\n",
       "      <td>1</td>\n",
       "      <td>wizard</td>\n",
       "      <td>30</td>\n",
       "      <td>37.5</td>\n",
       "      <td>14.880476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>gondor</td>\n",
       "      <td>2</td>\n",
       "      <td>wizard</td>\n",
       "      <td>30</td>\n",
       "      <td>37.5</td>\n",
       "      <td>14.880476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>gondor</td>\n",
       "      <td>5</td>\n",
       "      <td>warrior</td>\n",
       "      <td>50</td>\n",
       "      <td>37.5</td>\n",
       "      <td>14.880476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>gondor</td>\n",
       "      <td>7</td>\n",
       "      <td>priest</td>\n",
       "      <td>10</td>\n",
       "      <td>37.5</td>\n",
       "      <td>14.880476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>gondor</td>\n",
       "      <td>9</td>\n",
       "      <td>wizard</td>\n",
       "      <td>30</td>\n",
       "      <td>37.5</td>\n",
       "      <td>14.880476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>gondor</td>\n",
       "      <td>10</td>\n",
       "      <td>priest</td>\n",
       "      <td>10</td>\n",
       "      <td>37.5</td>\n",
       "      <td>14.880476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>gondor</td>\n",
       "      <td>11</td>\n",
       "      <td>wizard</td>\n",
       "      <td>30</td>\n",
       "      <td>37.5</td>\n",
       "      <td>14.880476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>mordor</td>\n",
       "      <td>0</td>\n",
       "      <td>warrior</td>\n",
       "      <td>50</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.148542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>mordor</td>\n",
       "      <td>3</td>\n",
       "      <td>priest</td>\n",
       "      <td>10</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.148542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>mordor</td>\n",
       "      <td>4</td>\n",
       "      <td>warrior</td>\n",
       "      <td>50</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.148542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>mordor</td>\n",
       "      <td>6</td>\n",
       "      <td>warrior</td>\n",
       "      <td>50</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.148542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>mordor</td>\n",
       "      <td>8</td>\n",
       "      <td>warrior</td>\n",
       "      <td>50</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.148542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      land  id category  puntos de vida   avg     stddev\n",
       "0   gondor   1   wizard              30  37.5  14.880476\n",
       "1   gondor   2   wizard              30  37.5  14.880476\n",
       "2   gondor   5  warrior              50  37.5  14.880476\n",
       "3   gondor   7   priest              10  37.5  14.880476\n",
       "4   gondor   9   wizard              30  37.5  14.880476\n",
       "5   gondor  10   priest              10  37.5  14.880476\n",
       "6   gondor  11   wizard              30  37.5  14.880476\n",
       "7   mordor   0  warrior              50  25.0  19.148542\n",
       "8   mordor   3   priest              10  25.0  19.148542\n",
       "9   mordor   4  warrior              50  25.0  19.148542\n",
       "10  mordor   6  warrior              50  25.0  19.148542\n",
       "11  mordor   8  warrior              50  25.0  19.148542"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas = annotated.toPandas()\n",
    "pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ojo__: esto lo trae a la memoría del nodo driver (del master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el otro sentido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[land: string, id: bigint, category: string, puntos de vida: bigint, avg: double, stddev: double]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
